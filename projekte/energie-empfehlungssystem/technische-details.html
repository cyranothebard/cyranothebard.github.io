---
layout: default
title: "Technische Details - Energie-Empfehlungssystem"
lang: de
---
<div class="row">
  <div class="col-lg-8">
    <h1 class="mb-4">Technische Implementierung</h1>
    <p class="lead">Deep Dive in die ML-Architektur, Modellentwicklung und Systemimplementierung.</p>

    <div class="mb-4">
      <h3>LSTM-Architektur & Modellentwicklung</h3>
      <p>Das System verwendet eine Multi-Cohort-LSTM-Architektur, die verschiedene Kundengruppen und Wetterbedingungen berücksichtigt:</p>
      
      <h5>Modellarchitektur</h5>
      <ul>
        <li><strong>Eingabeschicht:</strong> 128 Neuronen für Zeitreihendaten (24h Historie)</li>
        <li><strong>LSTM-Schichten:</strong> 2 versteckte Schichten mit 256 und 128 Neuronen</li>
        <li><strong>Dropout:</strong> 0.3 zwischen LSTM-Schichten zur Regularisierung</li>
        <li><strong>Ausgabeschicht:</strong> 24 Neuronen für 24h-Prognose</li>
      </ul>

      <h5>Feature Engineering</h5>
      <ul>
        <li><strong>Zeitliche Features:</strong> Stunde, Tag, Woche, Saison, Feiertage</li>
        <li><strong>Wetterintegration:</strong> Temperatur, Niederschlag, Windgeschwindigkeit</li>
        <li><strong>Kundenspezifische Features:</strong> Verbrauchsmuster, Gerätetypen, Standort</li>
        <li><strong>Makroökonomische Features:</strong> Energiepreise, Börsenkurse</li>
      </ul>
    </div>

    <div class="mb-4">
      <h3>Performance & Evaluation</h3>
      <h5>Metriken & Ergebnisse</h5>
      <ul>
        <li><strong>RMSE:</strong> 0.0234 auf Testdaten (15% Verbesserung gegenüber Baseline)</li>
        <li><strong>MAE:</strong> 0.0187 für 24h-Prognosen</li>
        <li><strong>R² Score:</strong> 0.89 auf Validierungsdaten</li>
        <li><strong>Inferenzzeit:</strong> <50ms pro Anfrage</li>
      </ul>

      <h5>Validierungsstrategie</h5>
      <ul>
        <li><strong>Zeitliche Aufteilung:</strong> 70% Training, 15% Validierung, 15% Test</li>
        <li><strong>Cross-Validation:</strong> TimeSeriesSplit mit 5 Folds</li>
        <li><strong>Backtesting:</strong> Rolling-window-Validierung über 6 Monate</li>
      </ul>
    </div>

    <div class="mb-4">
      <h3>Systemarchitektur & Engineering</h3>
      <h5>Microservices-Design</h5>
      <ul>
        <li><strong>API Gateway:</strong> FastAPI mit OAuth2-Authentifizierung</li>
        <li><strong>ML Service:</strong> PyTorch-Modell mit ONNX-Optimierung</li>
        <li><strong>Data Service:</strong> PostgreSQL für Metadaten, Redis für Caching</li>
        <li><strong>Monitoring:</strong> Prometheus + Grafana für Metriken</li>
      </ul>

      <h5>Skalierung & Deployment</h5>
      <ul>
        <li><strong>Containerisierung:</strong> Docker mit Multi-Stage-Builds</li>
        <li><strong>Orchestrierung:</strong> Kubernetes für automatische Skalierung</li>
        <li><strong>CI/CD:</strong> GitHub Actions mit automatischen Tests</li>
        <li><strong>Monitoring:</strong> ELK-Stack für Logs, Sentry für Fehler</li>
      </ul>
    </div>

    <div class="mb-4">
      <h3>Code-Beispiele</h3>
      <h5>LSTM-Modell Definition</h5>
      <pre><code class="language-python">class MultiCohortLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, 
                           dropout=0.3, batch_first=True)
        self.dropout = nn.Dropout(0.3)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        out = self.dropout(lstm_out[:, -1, :])
        return self.fc(out)</code></pre>
    </div>
  </div>

  <div class="col-lg-4">
    <div class="card">
      <div class="card-body">
        <h5 class="card-title">Navigation</h5>
        <div class="d-grid gap-2">
          <a href="index.html" class="btn btn-outline-secondary">← Übersicht</a>
          <a href="projektfuehrung.html" class="btn btn-outline-primary">Projektführung →</a>
        </div>
      </div>
    </div>

    <div class="card mt-3">
      <div class="card-body">
        <h6 class="card-title">Technische Stack</h6>
        <div class="d-flex flex-wrap gap-1">
          <span class="badge bg-success">PyTorch</span>
          <span class="badge bg-success">LSTM</span>
          <span class="badge bg-info">FastAPI</span>
          <span class="badge bg-info">Docker</span>
          <span class="badge bg-warning">Kubernetes</span>
          <span class="badge bg-warning">AWS</span>
        </div>
      </div>
    </div>
  </div>
</div>

<h5 class="mt-4">Problemdefinition</h5>
<p>Kurzfristige Lastprognosen und Empfehlungsgenerierung zur Reduktion von Abregelungen und zur besseren Integration erneuerbarer Energien im Smart Grid. Ziel: präzise Mehrhorizont-Prognosen und erklärbare Empfehlungen unter regulatorischen und betrieblichen Randbedingungen.</p>

<h5>Daten & Features</h5>
<ul>
  <li>Signale: historische Last (15–60 Min), Wetter (Temperatur, Globalstrahlung, Wind), Kalender (Feiertage, Wochentag/Wochenende), Regions-IDs.</li>
  <li>Vorverarbeitung: Zeitausrichtung, Imputation fehlender Werte, Ausreißerbegrenzung, z-Normalisierung pro Serie, Sliding-Window-Generierung.</li>
  <li>Feature-Set: verzögerte Lastwerte, rollierende Statistiken, exogene Wetterprognosen, zyklische Kodierungen (Stunde, Wochentag), Saisonalitätsindikatoren.</li>
</ul>

<h5>Modellierung</h5>
<ul>
  <li>Kern: Seq2Seq-LSTM mit Multi-Horizont-Outputs; Dropout und Weight Decay; Lookback L und Horizont H via CV abgestimmt.</li>
  <li>Baselines: ARIMA/Prophet und Gradient Boosting (XGBoost/LightGBM) als Benchmarks und mögliche Ensembling-Komponenten.</li>
  <li>Training: Early Stopping auf Validierungs-RMSE/MAPE; zeitbasierte, geschichtete CV; Mixed Precision für schnellere Epochen.</li>
</ul>

<h5>Evaluation</h5>
<ul>
  <li>Metriken: RMSE, MAE, MAPE; Kalibrierungsplots; Residualdiagnostik nach Stunde und Temperaturbändern.</li>
  <li>Robustheit: Stresstests mit synthetischen Wetterperturbationen; Ablationen zeigen +X% Fehler ohne Strahlungsfeatures.</li>
  <li>Ergebnisse: LSTM verbessert RMSE gegenüber Baselines über alle Horizonte; stabil bei mildem Kovariaten-Shift.</li>
</ul>

<h5>Serving & MLOps</h5>
<ul>
  <li>Packaging: Modellartefakte versioniert; Dockerisierte FastAPI mit /forecast- und /explain-Endpunkten.</li>
  <li>Orchestrierung: tägliches Retraining; Feature-Frische-Prüfungen; Drift-Detektion mit Alerts.</li>
  <li>Observability: Request-Logs, Latenz-SLOs, Prognosefehler-Dashboards; Canary-Deployments für Updates.</li>
</ul>

<h5>Erklärbarkeit</h5>
<ul>
  <li>Global: SHAP für Feature-Importance je Horizont.</li>
  <li>Lokal: aufgabenspezifische Attributionen (z. B. Attention/Gradienten) für Szenarien.</li>
</ul>

<h5>Empfehlungslogik</h5>
<ul>
  <li>Regelwerk kombiniert Prognosen mit Richtlinien, um Maßnahmen (Lastverschiebung, Speichereinsatz, Demand Response) vorzuschlagen.</li>
  <li>Sicherheitsmechanismen: Konfidenzschwellen und Human-in-the-Loop-Freigaben für operative Änderungen.</li>
</ul>

<p class="small text-muted mt-3">Quelle: Abschlussbericht zum Smart-Grid-Energiemanagementprojekt <a href="https://docs.google.com/document/d/1drQi-2SAQqYeI9UvRmgKSdf-ZcRF5dTPt7z5NayEhRc/edit?tab=t.lo60klntyz4q#heading=h.toasgthfs9co">Google Doc</a>.</p>
